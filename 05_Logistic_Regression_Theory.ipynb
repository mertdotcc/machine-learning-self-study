{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "(Refer to the __Chapters 4__-__4.3__ of __Introduction to Statistical Learning__ by __Gareth James__).\n",
    "<br><br>\n",
    "* We are going to tackle Logistic Regression as as method for __classification__.\n",
    "<br><br>\n",
    "* In machine learning and statistics, classification is the problem of identifying to which of a set of categories a new observation belongs to based off of training data.\n",
    "<br><br>\n",
    "* Some examples of classification problems:\n",
    "    * Spam versus ham\n",
    "    * Loan default (yes/no)\n",
    "    * Disease Diagnosis\n",
    "<br><br>\n",
    "* Above were all examples of Binary Classification.\n",
    "***\n",
    "* In regression problems, we tried to predict a continuous value.\n",
    "<br><br>\n",
    "* Although the name may be confusing at first, logistic regression allows us to solve classification problems, where we are trying to predict discrete categories.\n",
    "<br><br>\n",
    "* The convention for binary classification is to have two classes 0 and 1.\n",
    "<br><br>\n",
    "* See from the picture below that we cannot use a normal linear regression model on binary groups. It won't lead to a good fit.\n",
    "![title](images/v5.png)\n",
    "<br><br>\n",
    "* Instead, we can transform our linear regression to a __logistic regression curve__.\n",
    "![title](images/v6.png)\n",
    "<br><br>\n",
    "* The __Sigmoid__ (a.k.a. Logistic) function takes in any value and outputs it to be between 0 and 1.\n",
    "![title](images/v7.png)\n",
    "<br><br>\n",
    "* This means that we can take our Linear Regression solution and place it into the Sigmoid function.\n",
    "![title](images/v8.png)\n",
    "<br><br>\n",
    "* We can set a cutoff point at 0.5 so that anything below it results in class 0, anything above in class 1.\n",
    "![title](images/v9.png)\n",
    "<br><br>\n",
    "* After we train a logistic regression model on some training data, we are going to test our model's performance on some test data.\n",
    "<br><br>\n",
    "* We can use a __confusion matrix__ to evaluate classification models.\n",
    "***\n",
    "### Quick Recap on Confusion Matrixes\n",
    "* We can use a confusion matrix to evaluate our model. Consider the well-known disease-dataset.\n",
    "![title](images/v11.png)\n",
    "<br><br>\n",
    "![title](images/v12.png)\n",
    "<br><br>\n",
    "* __Basic Terminology:__\n",
    "    * __True Positives (TP)__\n",
    "    * __True Negatives (TN)__\n",
    "    * __False Positives (FP)__\n",
    "    * __False Negatives (FN)__\n",
    "<br><br>\n",
    "* To calculate how accurate our model is, we would do __(TP + TN) / total__ which is __150/165 ~= 0.91__ in this case.\n",
    "<br><br>\n",
    "* And simply to calculate the __Misclassification Rate (Error Rate)__ we would do __(FP + FN) / total__ which is __15/165 ~= 0.09__ in this case.\n",
    "<br><br>\n",
    "* To think of False Positives And False Negatives:\n",
    "![title](images/v13.png)\n",
    "End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
